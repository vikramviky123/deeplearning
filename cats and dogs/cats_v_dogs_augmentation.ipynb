{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3qDax7R0BBK"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-1-public/blob/master/C2/W2/ungraded_labs/C2_W2_Lab_1_cats_v_dogs_augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJJqX4DxcQs8"
      },
      "source": [
        "## Baseline Performance\n",
        "\n",
        "You will start with a model that's very effective at learning `Cats vs Dogs` without data augmentation. It's similar to the previous models that you have used. Note that there are four convolutional layers with 32, 64, 128 and 128 convolutions respectively. The code is basically the same from the previous lab so we won't go over the details step by step since you've already seen it before.\n",
        "\n",
        "You will train only for 20 epochs to save time but feel free to increase this if you want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJZIF29-dIRv"
      },
      "outputs": [],
      "source": [
        "# Download the dataset\n",
        "# !wget https://storage.googleapis.com/tensorflow-1-public/course2/cats_and_dogs_filtered.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sw0D5tdH0BBR"
      },
      "outputs": [],
      "source": [
        "from helper import *\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import zipfile\n",
        "import requests\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "\n",
        "def splits(dataset, TRAIN_RATIO, VAL_RATIO):\n",
        "    DATASET_SIZE = len(dataset)\n",
        "\n",
        "    train_dataset = dataset.take(int(TRAIN_RATIO*DATASET_SIZE))\n",
        "\n",
        "    val_test_dataset = dataset.skip(int(TRAIN_RATIO*DATASET_SIZE))\n",
        "    val_dataset = val_test_dataset.take(int(VAL_RATIO*DATASET_SIZE))\n",
        "\n",
        "    return train_dataset, val_dataset\n",
        "\n",
        "\n",
        "def download_zip_file(url: str, save_path: Path):\n",
        "    response = requests.get(url)\n",
        "\n",
        "    fileDir, fileName = os.path.split(save_path)\n",
        "\n",
        "    os.makedirs(fileDir, exist_ok=True)\n",
        "\n",
        "    # Check if the request was successful (status code 200)\n",
        "    if response.status_code == 200:\n",
        "        with open(save_path, 'wb') as file:\n",
        "            file.write(response.content)\n",
        "        print(f\"Download successful. File saved at {save_path}\")\n",
        "    else:\n",
        "        print(f\"Error {response.status_code}: Unable to download the file.\")\n",
        "\n",
        "\n",
        "def extract_zip_file(zip_file_path, extract_path):\n",
        "\n",
        "    fileDir, fileName = os.path.split(extract_path)\n",
        "    os.makedirs(fileDir, exist_ok=True)\n",
        "\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    print(f\"Extraction successful. Files extracted to {extract_path}\")\n"
      ],
      "metadata": {
        "id": "awm5XX6b0VHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXF477pm0BBR"
      },
      "outputs": [],
      "source": [
        "url = \"https://storage.googleapis.com/tensorflow-1-public/course2/cats_and_dogs_filtered.zip\"\n",
        "\n",
        "zip_file_path = Path('data/cats_and_dogs.zip')\n",
        "extract_path = Path('data/')\n",
        "\n",
        "download_zip_file(url,zip_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SByMdJ0v0BBS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Extract the archive\n",
        "zip_ref = zipfile.ZipFile(zip_file_path, 'r')\n",
        "zip_ref.extractall(extract_path)\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DyUfCTgdwa8"
      },
      "outputs": [],
      "source": [
        "# Assign training and validation set directories\n",
        "base_dir = 'data/cats_and_dogs_filtered'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# Directory with training cat pictures\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "\n",
        "# Directory with training dog pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "# Directory with validation cat pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "\n",
        "# Directory with validation dog pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlNwoqK30BBT"
      },
      "outputs": [],
      "source": [
        "tr_cats = len(os.listdir(train_cats_dir))\n",
        "tr_dogs = len(os.listdir(train_dogs_dir))\n",
        "\n",
        "vl_cats = len(os.listdir(validation_cats_dir))\n",
        "vl_dogs = len(os.listdir(validation_dogs_dir))\n",
        "\n",
        "print(\"Length of training for CATS is \",tr_cats,\"and for DOGS\",tr_dogs)\n",
        "print(\"Length of Validation for CATS is \", vl_cats, \"and for DOGS\",vl_dogs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ub_BdOJIfZ_Q"
      },
      "source": [
        "You will place the model creation inside a function so you can easily initialize a new one when you use data augmentation later in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWllK_Wad-Mx"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.layers import Rescaling\n",
        "\n",
        "\n",
        "def create_model():\n",
        "    '''Creates a CNN with 4 convolutional layers'''\n",
        "    model = tf.keras.models.Sequential([\n",
        "        Rescaling(1./255, input_shape=(150, 150, 3)),\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        # Use softmax activation for categorical labels\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer=RMSprop(learning_rate=1e-4),\n",
        "                  metrics=['binary_accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJPyDEzOqrKB"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# All images will be rescaled by 1./255\n",
        "train_datagen = ImageDataGenerator(\n",
        "                                        rotation_range=40,\n",
        "                                        width_shift_range=0.2,\n",
        "                                        height_shift_range=0.2,\n",
        "                                        shear_range=0.2,\n",
        "                                        zoom_range=0.2,\n",
        "                                        horizontal_flip=True,\n",
        "                                        fill_mode='nearest')\n",
        "test_datagen = ImageDataGenerator()\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,  # This is the source directory for training images\n",
        "        target_size=(150, 150),  # All images will be resized to 150x150\n",
        "        batch_size=20,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')\n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_u0bOzO0BBU"
      },
      "outputs": [],
      "source": [
        "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    batch_size=20,\n",
        "    image_size=(150, 150),\n",
        "    shuffle=True,\n",
        "    seed=99,\n",
        ")\n",
        "\n",
        "val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    validation_dir,\n",
        "    batch_size=20,  # CONFIGURATION[\"BATCH_SIZE\"],\n",
        "    image_size=(150, 150),\n",
        "    shuffle=True,\n",
        "    seed=99,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_dataset.class_names\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "_Yjr5IuM8MWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_dataset.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "QNF7Vus785Hh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image_batch, labels_batch in train_dataset:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ],
      "metadata": {
        "id": "y_f5C4LR9Q-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(train_dataset.take(1).as_numpy_iterator())[0][1].shape, list(train_dataset.take(1).as_numpy_iterator())[0][0].shape"
      ],
      "metadata": {
        "id": "7G3IrbuT1vvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4I9akK70BBV"
      },
      "outputs": [],
      "source": [
        "tf_2d = tf.constant(\n",
        "    [[1, 2, 3],\n",
        "     [1, 2, 3],\n",
        "     [1, 2, 3]],\n",
        "    dtype=\"float32\",\n",
        ")\n",
        "tf_2d[:,-1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zP1ztc9h0BBV"
      },
      "outputs": [],
      "source": [
        "def resize_rescale(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    return tf.squeeze(image), tf.squeeze(tf.squeeze(label)[:, -1:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1QOc4J60BBV"
      },
      "outputs": [],
      "source": [
        "train_data = (train_dataset\n",
        "              .cache()\n",
        "              .shuffle(buffer_size=512, reshuffle_each_iteration=True)\n",
        "              .prefetch(tf.data.AUTOTUNE))\n",
        "\n",
        "val_data = (val_dataset\n",
        "              .cache()\n",
        "              .shuffle(buffer_size=512, reshuffle_each_iteration=True)\n",
        "              .prefetch(tf.data.AUTOTUNE))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_pp0oFA0BBV"
      },
      "outputs": [],
      "source": [
        "list(train_data.take(1).as_numpy_iterator())[0][1].shape, list(train_data.take(1).as_numpy_iterator())[0][0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iE-YAW560BBV"
      },
      "outputs": [],
      "source": [
        "# Constant for epochs\n",
        "EPOCHS = 40\n",
        "\n",
        "# Create a new model\n",
        "model = create_model()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    steps_per_epoch=100,  # 2000 images = batch_size * steps\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_data,\n",
        "    validation_steps=50,  # 1000 images = batch_size * steps\n",
        "    verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdqUoF44esR3"
      },
      "outputs": [],
      "source": [
        "# Constant for epochs\n",
        "EPOCHS = 40\n",
        "\n",
        "# Create a new model\n",
        "model = create_model()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=100,  # 2000 images = batch_size * steps\n",
        "      epochs=EPOCHS,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=50,  # 1000 images = batch_size * steps\n",
        "      verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-G0Am4cguNt"
      },
      "source": [
        "You will then visualize the loss and accuracy with respect to the training and validation set. You will again use a convenience function so it can be reused later. This function accepts a [History](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History) object which contains the results of the `fit()` method you ran above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRqRBaej0BBW"
      },
      "outputs": [],
      "source": [
        "history.history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZWPcmKWO303"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss_acc(history):\n",
        "  '''Plots the training and validation loss and accuracy from a history object'''\n",
        "  acc = history.history['binary_accuracy']\n",
        "  val_acc = history.history['val_binary_accuracy']\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  epochs = range(len(acc))\n",
        "\n",
        "  plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "  plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "  plt.title('Training and validation accuracy')\n",
        "\n",
        "  plt.figure()\n",
        "\n",
        "  plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
        "  plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vojz4NYXiT_f"
      },
      "outputs": [],
      "source": [
        "# Plot training results\n",
        "plot_loss_acc(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLPGG8JF0BBW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "C2_W2_Lab_1_cats_v_dogs_augmentation.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}